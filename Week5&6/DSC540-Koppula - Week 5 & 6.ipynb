{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5&6 (Veera Reddy Koppula)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lesson 5 - Activity 7, page 207** In this activity you are given the Wikipedia page where we have the GDP of all countries listed and you are asked to create three data frames from the three sources mentioned in the page ( link - https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal) )\n",
    "\n",
    "You will have to -\n",
    "\n",
    "- Open the page in a separate chrome/firefox tab and use something like `inspect element` tool to see the source HTML and understand the structure\n",
    "- Read the page using bs4\n",
    "- Find the table structure you will need to deal with (how many tables are there)\n",
    "- Find the right table using bs4\n",
    "- Separate the Source Names and their corresponding data\n",
    "- Get the source names from the list of sources you have created\n",
    "- Seperate the header and data from the data that you separated before. For the first source only. And then create a DataFrame using that\n",
    "- Repeat the last task for the other two data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read the page Wikipedia page with GDP of all countries using bs4 package**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import BueautifulSoup for scraping web data and Padas for working with data\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open GDP of all countries listed from wikipedia in read mode\n",
    "fd = open(\"List of countries by GDP (nominal) - Wikipedia.htm\", \"r\")\n",
    "soup = BeautifulSoup(fd)\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find the table structure you will need to deal with (how many tables are there)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tables are 9 \n"
     ]
    }
   ],
   "source": [
    "# Scraping source for all the tables & printing the count\n",
    "all_tables = soup.find_all(\"table\")\n",
    "print(\"Total number of tables are {} \".format(len(all_tables)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find the right table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Tag'>\n"
     ]
    }
   ],
   "source": [
    "# After inspecting the elements - loading the below table \n",
    "#class=\"wikitable sortable static-row-numbers plainrowheaders srn-white-background jquery-tablesorter\"\n",
    "data_table = soup.find(\"table\", {\"class\": '\"wikitable\"|}'})\n",
    "print(type(data_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separate the Source Names and their corresponding data** (in the table header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# finding all the source names and forming the list of sources\n",
    "sources = data_table.tbody.findAll('tr', recursive=False)[0]\n",
    "sources_list = [td for td in sources.findAll('td')]\n",
    "print(len(sources_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving all the data into a table\n",
    "data = data_table.tbody.findAll('tr', recursive=False)[1].findAll('td', recursive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperating data by source and appending corresponding data into data_tables list\n",
    "data_tables = []\n",
    "for td in data:\n",
    "    data_tables.append(td.findAll('table'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#length of data_tables list\n",
    "len(data_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the source names from the list of sources you have created**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['International Monetary Fund', 'World Bank', 'United Nations']\n"
     ]
    }
   ],
   "source": [
    "# All the tags that have an 'a' in html tag are source names\n",
    "source_names = [source.findAll('a')[0].getText() for source in sources_list]\n",
    "print(source_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seperate the header and data from the data that you separated before. For the first source only. And then create a DataFrame using that** (International Monetary Fund)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rank', 'Country', 'GDP(US$MM)']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forming the header from first list of data_table list of list  - which corresponds to first source \"IMF\"\n",
    "header1 = [th.getText().strip() for th in data_tables[0][0].findAll('thead')[0].findAll('th')]\n",
    "header1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extractig the data rows from table from first list of list (correspodning to IMF)\n",
    "rows1 = data_tables[0][0].findAll('tbody')[0].findAll('tr')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stripping away text and saving the data\n",
    "data_rows1 = [[td.get_text().strip() for td in tr.findAll('td')] for tr in rows1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forming a data from from the \"IMF\" stripped data and appending header from the header List extracted above\n",
    "df1 = pd.DataFrame(data_rows1, columns=header1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Country</th>\n",
       "      <th>GDP(US$MM)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "      <td>19,390,600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>China[n 1]</td>\n",
       "      <td>12,014,610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Japan</td>\n",
       "      <td>4,872,135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Germany</td>\n",
       "      <td>3,684,816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2,624,529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank         Country  GDP(US$MM)\n",
       "0    1   United States  19,390,600\n",
       "1    2      China[n 1]  12,014,610\n",
       "2    3           Japan   4,872,135\n",
       "3    4         Germany   3,684,816\n",
       "4    5  United Kingdom   2,624,529"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing top rows from the data frame\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repeat the last task for the other two data sources** (World Bank and UN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rank', 'Country', 'GDP(US$MM)']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract headers from second list - corresponding to second soure \"world bank\"\n",
    "header2 = [th.getText().strip() for th in data_tables[1][0].findAll('thead')[0].findAll('th')]\n",
    "header2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extractig the data rows from table from first list of list (correspodning to \"world Bank\")\n",
    "rows2 = data_tables[1][0].findAll('tbody')[0].findAll('tr')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When observed closely there are special charecters in the data table for \"world bank\"\n",
    "#below function is used to strip text and the special charecters\n",
    "def find_right_text(i, td):\n",
    "    if i == 0:\n",
    "        return td.getText().strip()\n",
    "    elif i == 1:\n",
    "        return td.getText().strip()\n",
    "    else:\n",
    "        index = td.text.find(\"♠\")\n",
    "        return td.text[index+1:].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stripping away text and saving the data\n",
    "data_rows2 = [[find_right_text(i, td) for i, td in enumerate(tr.findAll('td'))] for tr in rows2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forming a data from from the \"World Bank\" stripped data and appending header from the header List extracted above\n",
    "df2 = pd.DataFrame(data_rows2, columns=header2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Country</th>\n",
       "      <th>GDP(US$MM)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "      <td>19,390,604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>European Union[23]</td>\n",
       "      <td>17,277,698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>China[n 4]</td>\n",
       "      <td>12,237,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Japan</td>\n",
       "      <td>4,872,137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Germany</td>\n",
       "      <td>3,677,439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank             Country  GDP(US$MM)\n",
       "0    1       United States  19,390,604\n",
       "1       European Union[23]  17,277,698\n",
       "2    2          China[n 4]  12,237,700\n",
       "3    3               Japan   4,872,137\n",
       "4    4             Germany   3,677,439"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing top rows from the data frame\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rank', 'Country', 'GDP(US$MM)']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract headers from third list - corresponding to second soure \"UN\"\n",
    "header3 = [th.getText().strip() for th in data_tables[2][0].findAll('thead')[0].findAll('th')]\n",
    "header3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extractig the data rows from table from third list of list (correspodning to UN)\n",
    "#There are special charecters similar to World Bank data - so we need to strip them away\n",
    "rows3 = data_tables[2][0].findAll('tbody')[0].findAll('tr')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stripping away text and special charectars (Using same as World Bank Data)\n",
    "data_rows3 = [[find_right_text(i, td) for i, td in enumerate(tr.findAll('td'))] for tr in rows3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forming a data from from the \"UN\" stripped data and appending header from the header List extracted above\n",
    "df3 = pd.DataFrame(data_rows3, columns=header3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Country</th>\n",
       "      <th>GDP(US$MM)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "      <td>18,624,475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>China[n 4]</td>\n",
       "      <td>11,218,281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Japan</td>\n",
       "      <td>4,936,211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Germany</td>\n",
       "      <td>3,477,796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2,647,898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank         Country  GDP(US$MM)\n",
       "0    1   United States  18,624,475\n",
       "1    2      China[n 4]  11,218,281\n",
       "2    3           Japan   4,936,211\n",
       "3    4         Germany   3,477,796\n",
       "4    5  United Kingdom   2,647,898"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing top rows from the data frame\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lesson 06 - Activity 8, page 233**\n",
    "\n",
    "In this activity, we will identify and get rid of outliers. Here, we have a CSV file. The goal here is to clean the data by using the knowledge that we have learned about so far and come up with a nicely formatted DataFrame. Identify the type of outliers and their effect on the data and clean the messy data.\n",
    "The steps that will help you solve this activity are as follows:\n",
    "1. Read the visit_data.csv file.\n",
    "2. Check for duplicates.\n",
    "3. Check if any essential column contains NaN.\n",
    "4. Get rid of the outliers.\n",
    "5. Report the size difference.\n",
    "6. Create a box plot to check for outliers.\n",
    "7. Get rid of any outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a data frame from visit_data CSV**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Import needed packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Visit data csv into a data frame using pandas\n",
    "df = pd.read_csv(\"visit_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>gender</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>visit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Sonny</td>\n",
       "      <td>Dahl</td>\n",
       "      <td>sdahl0@mysql.com</td>\n",
       "      <td>Male</td>\n",
       "      <td>135.36.96.183</td>\n",
       "      <td>1225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dhoovart1@hud.gov</td>\n",
       "      <td>NaN</td>\n",
       "      <td>237.165.194.143</td>\n",
       "      <td>919.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Gar</td>\n",
       "      <td>Armal</td>\n",
       "      <td>garmal2@technorati.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166.43.137.224</td>\n",
       "      <td>271.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Chiarra</td>\n",
       "      <td>Nulty</td>\n",
       "      <td>cnulty3@newyorker.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>139.98.137.108</td>\n",
       "      <td>1002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sleaver4@elegantthemes.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.117.117.27</td>\n",
       "      <td>2434.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id first_name last_name                       email gender  \\\n",
       "0   1      Sonny      Dahl            sdahl0@mysql.com   Male   \n",
       "1   2        NaN       NaN           dhoovart1@hud.gov    NaN   \n",
       "2   3        Gar     Armal      garmal2@technorati.com    NaN   \n",
       "3   4    Chiarra     Nulty       cnulty3@newyorker.com    NaN   \n",
       "4   5        NaN       NaN  sleaver4@elegantthemes.com    NaN   \n",
       "\n",
       "        ip_address   visit  \n",
       "0    135.36.96.183  1225.0  \n",
       "1  237.165.194.143   919.0  \n",
       "2   166.43.137.224   271.0  \n",
       "3   139.98.137.108  1002.0  \n",
       "4    46.117.117.27  2434.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prining top rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check for duplicates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First name has duplicates? - True\n",
      "Last name has duplicates? - True\n",
      "Email has duplicates? - False\n"
     ]
    }
   ],
   "source": [
    "#Checking if there duplicates in First Name, Last Name and email columns\n",
    "print(\"First name has duplicates? - {}\".format(any(df.first_name.duplicated())))\n",
    "print(\"Last name has duplicates? - {}\".format(any(df.last_name.duplicated())))\n",
    "print(\"Email has duplicates? - {}\".format(any(df.email.duplicated())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are duplicates in both First and Last names, which could be expected. However there are no duplicate email id rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check if any essential column contains NaN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column Email contains NaN - False \n",
      "The column IP Address contains NaN - False \n",
      "The column Visit contains NaN - True \n"
     ]
    }
   ],
   "source": [
    "# Checking if there are any NaN values in important columns\n",
    "print(\"The column Email contains NaN - %r \" % df.email.isnull().values.any())\n",
    "print(\"The column IP Address contains NaN - %s \" % df.ip_address.isnull().values.any())\n",
    "print(\"The column Visit contains NaN - %s \" % df.visit.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are to use this data set meaningfully, we would need to be able to identify unique email address and IPs visiting the site and the duration of visit. In the current set column visit contains some None values, these rows will be unusable outliers for generating insights on the number and duration of visits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get rid of the outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving a backup of original data & calculating the size\n",
    "df_orig = df\n",
    "size_orig = df_orig.shape\n",
    "#Stripping none values in visit column and saving back to current data set\n",
    "df = df[np.isfinite(df['visit'])]\n",
    "#calculating size of the data after clean-up\n",
    "size_cleaned = df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Report the size difference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of previous data was - 1000 rows and the size of the new one is - 974 rows\n"
     ]
    }
   ],
   "source": [
    "print(\"The size of previous data was - {prev[0]} rows and the size of the new one is - {after[0]} rows\".\n",
    "      format(prev=size_orig, after=size_cleaned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a box plot to check for outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x7fc128d95bb0>,\n",
       "  <matplotlib.lines.Line2D at 0x7fc128d95f10>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x7fc128da32b0>,\n",
       "  <matplotlib.lines.Line2D at 0x7fc128da3610>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x7fc128d95850>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x7fc128da3970>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x7fc128da3cd0>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Creating a box plot on visit column to check outliers\n",
    "plt.boxplot(df.visit, notch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see that we have data in this column in the interval (0, 3000). However, the main concentration of the data is between ~700 to ~2300. We could consuder data above 2900 and less than 100 as outliers and get rid of them for the purposes of further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get rid of any outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting rid of data with visit <=100 and >=2900\n",
    "df_final = df[(df['visit'] <= 2900) & (df['visit'] >= 100)]  # Notice the powerful & operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After getting rid of outliers the new size of the data is - 923\n"
     ]
    }
   ],
   "source": [
    "print(\"After getting rid of outliers the new size of the data is - {}\".format(*df_final.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Insert data into a SQL Lite database – create a table with the following data (Hint: Python for Data Analysis page 191):**\n",
    "\n",
    "a. Name, Address, City, State, Zip, Phone Number\n",
    "\n",
    "b. Add at least 10 rows of data and submit your code with a query generating your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing sqllite\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query outline to insert - Name, Address, City, State, Zip, Phone Number\n",
    "query = \"\"\"\n",
    "       .....: CREATE TABLE week5_task3\n",
    "       .....: (Name VARCHAR(20), Address VARCHAR(20),\n",
    "       .....:  City VARCHAR(20), State VARCHAR(2),\n",
    "       .....: Zip VARCHAR(10),PhoneNumber INTEGER);\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a sqllite db connection to temp schema \"mydata.sqllite\"\n",
    "con = sqlite3.connect('mydata.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7fc1296f0c70>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#opening cursor for query execution to create the table\n",
    "con.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Commit after create table\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data set to insert 11 rows of data\n",
    "data = [('Sam Test', '123 Test Av', 'Atlanta', 'GA','30040',1231231234),\n",
    "        .....:         ('Tom Tommy', '123 George St', 'Salem', 'PA','19830',1231234567),\n",
    "        .....:         ('George C', '123 Hollywood Av', 'Los Angeles', 'CA','06671',12315781234),\n",
    "        .....:         ('Honey S', '676 Hollywood Av', 'Los Angeles', 'CA','06671',5781231234),\n",
    "        .....:         ('Amla Dean', '576 Casino Av', 'Los Vegas', 'NE','16671',1231333234),\n",
    "        .....:         ('Florida Cat', '323 Gaters Av', 'Miami', 'FL','99671',5555231234),\n",
    "        .....:         ('Party Sam', '9923 Bar Dr', 'New Orleans', 'LA','50001',1231244444),\n",
    "        .....:         ('Cheese Danish', '333 Cheese Cr', 'Milwaukee', 'WI','66671',1543451234),\n",
    "        .....:         ('Potato Fries', '6421 McDonalds Ct', 'Idaho City', 'IA','45891',6101231234),\n",
    "        .....:         ('Allegator Why', '33 Ocean Dr', 'Mobile', 'AL','06671',3145671234),\n",
    "        .....:         ('Dean Wright', '4565 Bingham Ct', 'Newark', 'DE','88898',8907651234),\n",
    "        .....:         ('Angela Wright', '4565 Bingham Ct', 'Newark', 'DE','88898',8902351234)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query statment to insert above data\n",
    "stmt = \"INSERT INTO week5_task3 VALUES(?, ?, ?, ?,?,?)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7fc1297140a0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Execution of insert statement query with data\n",
    "con.executemany(stmt, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Commit after data insert\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#execute select to get data stream onto cursor\n",
    "cursor = con.execute('select * from week5_task3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving returned sql db data into rows variable\n",
    "rows = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sam Test', '123 Test Av', 'Atlanta', 'GA', '30040', 1231231234),\n",
       " ('Tom Tommy', '123 George St', 'Salem', 'PA', '19830', 1231234567),\n",
       " ('George C', '123 Hollywood Av', 'Los Angeles', 'CA', '06671', 12315781234),\n",
       " ('Honey S', '676 Hollywood Av', 'Los Angeles', 'CA', '06671', 5781231234),\n",
       " ('Amla Dean', '576 Casino Av', 'Los Vegas', 'NE', '16671', 1231333234),\n",
       " ('Florida Cat', '323 Gaters Av', 'Miami', 'FL', '99671', 5555231234),\n",
       " ('Party Sam', '9923 Bar Dr', 'New Orleans', 'LA', '50001', 1231244444),\n",
       " ('Cheese Danish', '333 Cheese Cr', 'Milwaukee', 'WI', '66671', 1543451234),\n",
       " ('Potato Fries',\n",
       "  '6421 McDonalds Ct',\n",
       "  'Idaho City',\n",
       "  'IA',\n",
       "  '45891',\n",
       "  6101231234),\n",
       " ('Allegator Why', '33 Ocean Dr', 'Mobile', 'AL', '06671', 3145671234),\n",
       " ('Dean Wright', '4565 Bingham Ct', 'Newark', 'DE', '88898', 8907651234),\n",
       " ('Angela Wright', '4565 Bingham Ct', 'Newark', 'DE', '88898', 8902351234)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing all the data\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternate way to perform select query using sql alchemy package\n",
    "import sqlalchemy as sqla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forming sql connection to my sql db.\n",
    "db = sqla.create_engine('sqlite:///mydata.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>PhoneNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sam Test</td>\n",
       "      <td>123 Test Av</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30040</td>\n",
       "      <td>1231231234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tom Tommy</td>\n",
       "      <td>123 George St</td>\n",
       "      <td>Salem</td>\n",
       "      <td>PA</td>\n",
       "      <td>19830</td>\n",
       "      <td>1231234567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>George C</td>\n",
       "      <td>123 Hollywood Av</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>06671</td>\n",
       "      <td>12315781234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Honey S</td>\n",
       "      <td>676 Hollywood Av</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>06671</td>\n",
       "      <td>5781231234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amla Dean</td>\n",
       "      <td>576 Casino Av</td>\n",
       "      <td>Los Vegas</td>\n",
       "      <td>NE</td>\n",
       "      <td>16671</td>\n",
       "      <td>1231333234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Florida Cat</td>\n",
       "      <td>323 Gaters Av</td>\n",
       "      <td>Miami</td>\n",
       "      <td>FL</td>\n",
       "      <td>99671</td>\n",
       "      <td>5555231234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Party Sam</td>\n",
       "      <td>9923 Bar Dr</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>LA</td>\n",
       "      <td>50001</td>\n",
       "      <td>1231244444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cheese Danish</td>\n",
       "      <td>333 Cheese Cr</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>WI</td>\n",
       "      <td>66671</td>\n",
       "      <td>1543451234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Potato Fries</td>\n",
       "      <td>6421 McDonalds Ct</td>\n",
       "      <td>Idaho City</td>\n",
       "      <td>IA</td>\n",
       "      <td>45891</td>\n",
       "      <td>6101231234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Allegator Why</td>\n",
       "      <td>33 Ocean Dr</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>AL</td>\n",
       "      <td>06671</td>\n",
       "      <td>3145671234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dean Wright</td>\n",
       "      <td>4565 Bingham Ct</td>\n",
       "      <td>Newark</td>\n",
       "      <td>DE</td>\n",
       "      <td>88898</td>\n",
       "      <td>8907651234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Angela Wright</td>\n",
       "      <td>4565 Bingham Ct</td>\n",
       "      <td>Newark</td>\n",
       "      <td>DE</td>\n",
       "      <td>88898</td>\n",
       "      <td>8902351234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name            Address         City State    Zip  PhoneNumber\n",
       "0        Sam Test        123 Test Av      Atlanta    GA  30040   1231231234\n",
       "1       Tom Tommy      123 George St        Salem    PA  19830   1231234567\n",
       "2        George C   123 Hollywood Av  Los Angeles    CA  06671  12315781234\n",
       "3         Honey S   676 Hollywood Av  Los Angeles    CA  06671   5781231234\n",
       "4       Amla Dean      576 Casino Av    Los Vegas    NE  16671   1231333234\n",
       "5     Florida Cat      323 Gaters Av        Miami    FL  99671   5555231234\n",
       "6       Party Sam        9923 Bar Dr  New Orleans    LA  50001   1231244444\n",
       "7   Cheese Danish      333 Cheese Cr    Milwaukee    WI  66671   1543451234\n",
       "8    Potato Fries  6421 McDonalds Ct   Idaho City    IA  45891   6101231234\n",
       "9   Allegator Why        33 Ocean Dr       Mobile    AL  06671   3145671234\n",
       "10    Dean Wright    4565 Bingham Ct       Newark    DE  88898   8907651234\n",
       "11  Angela Wright    4565 Bingham Ct       Newark    DE  88898   8902351234"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selcting data from temp table week5_task3 and printing in a neat pandas dataframe format\n",
    "pd.read_sql('select * from week5_task3', db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
